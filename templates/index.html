<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title> Object Detection</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    /* Glassmorphism effect */
    .glass {
      background: rgba(255, 255, 255, 0.15);
      backdrop-filter: blur(12px);
      border: 1px solid rgba(255, 255, 255, 0.2);
    }
  </style>
</head>
<body class="bg-gradient-to-r from-indigo-600 via-purple-600 to-pink-600 min-h-screen flex flex-col items-center justify-center p-6">

  <!-- Title -->
  <h1 class="text-5xl md:text-6xl text-white font-extrabold mb-8 drop-shadow-lg tracking-wide text-center animate-pulse">
    Object Detection
  </h1>

  <!-- Upload Section -->
  <div class="glass p-6 rounded-2xl shadow-2xl mb-6 w-full max-w-lg text-center transition-transform hover:scale-105">
    <label for="file-input" class="cursor-pointer bg-gradient-to-r from-blue-500 to-blue-700 text-white py-3 px-6 rounded-xl shadow-lg hover:shadow-2xl transition duration-300 ease-in-out transform hover:-translate-y-1">
      ğŸ“ Upload Image
    </label>
    <input type="file" id="file-input" accept="image/*" class="hidden">
  </div>

  <!-- Camera Section -->
  <div class="glass p-6 rounded-2xl shadow-2xl mb-6 w-full max-w-lg text-center transition-transform hover:scale-105">
    <button id="open-camera" class="bg-gradient-to-r from-purple-500 to-purple-700 text-white py-3 px-6 rounded-xl shadow-lg hover:shadow-2xl transition duration-300 ease-in-out transform hover:-translate-y-1">
      ğŸ¥ Open Camera
    </button>
    <video id="camera" autoplay playsinline class="hidden mt-4 rounded-xl shadow-md w-full"></video>
    <div class="mt-4 space-x-2">
      <button id="capture-btn" class="hidden bg-gradient-to-r from-green-500 to-green-700 text-white py-3 px-6 rounded-xl shadow-lg hover:shadow-2xl transition duration-300 ease-in-out">
        ğŸ“¸ Capture
      </button>
      <button id="retake-btn" class="hidden bg-gradient-to-r from-red-500 to-red-700 text-white py-3 px-6 rounded-xl shadow-lg hover:shadow-2xl transition duration-300 ease-in-out">
        ğŸ”„ Retake
      </button>
    </div>
  </div>

  <!-- Results Section -->
  <div id="results-section" class="hidden glass p-6 rounded-2xl shadow-2xl w-full max-w-3xl text-center transition-transform hover:scale-105">
    <h2 class="text-3xl text-white font-bold mb-4">âœ¨ Detection Results</h2>
    <img id="processed-image" class="rounded-xl shadow-lg mb-4 w-full max-h-[500px] object-contain" src="">
    <p id="detected-text" class="text-lg text-yellow-200 font-semibold mb-4"></p>
    <button id="download-btn" class="bg-gradient-to-r from-yellow-400 to-yellow-600 text-white py-3 px-6 rounded-xl shadow-lg hover:shadow-2xl transition duration-300 ease-in-out">
      â¬‡ï¸ Download Result
    </button>
  </div>

  <script>
    const fileInput = document.getElementById("file-input");
    const openCameraBtn = document.getElementById("open-camera");
    const captureBtn = document.getElementById("capture-btn");
    const retakeBtn = document.getElementById("retake-btn");
    const video = document.getElementById("camera");
    const processedImage = document.getElementById("processed-image");
    const resultsSection = document.getElementById("results-section");
    const detectedText = document.getElementById("detected-text");
    const downloadBtn = document.getElementById("download-btn");

    let stream = null;

    // ğŸ”Š Speak results
    function speak(text) {
      const utterance = new SpeechSynthesisUtterance(`the image has ${text}`);
      utterance.rate = 0.9;
      window.speechSynthesis.speak(utterance);
    }

    // ğŸ“‚ Upload
    fileInput.addEventListener("change", () => {
      const file = fileInput.files[0];
      if (file) sendToServer(file);
    });

    // ğŸ“· Open Camera
    openCameraBtn.addEventListener("click", async () => {
      if (!stream) {
        stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        video.classList.remove("hidden");
        captureBtn.classList.remove("hidden");
        retakeBtn.classList.remove("hidden");
      }
    });

    // ğŸ–¼ Capture from Camera
    captureBtn.addEventListener("click", () => {
      const canvas = document.createElement("canvas");
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext("2d").drawImage(video, 0, 0);

      canvas.toBlob(blob => sendToServer(blob), "image/jpeg");
      stopCamera();
    });

    // ğŸ”„ Retake
    retakeBtn.addEventListener("click", async () => {
      stopCamera();
      stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
      video.classList.remove("hidden");
      captureBtn.classList.remove("hidden");
      retakeBtn.classList.remove("hidden");
    });

    // ğŸš« Stop camera
    function stopCamera() {
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
        stream = null;
      }
      video.classList.add("hidden");
      captureBtn.classList.add("hidden");
    }

    // ğŸ”— Send to Flask backend
    async function sendToServer(file) {
      const formData = new FormData();
      formData.append("image", file);

      const res = await fetch("/predict", { method: "POST", body: formData });
      const data = await res.json();

      processedImage.src = "data:image/jpeg;base64," + data.image;
      detectedText.textContent = data.text;
      resultsSection.classList.remove("hidden");

      speak(data.text);

      // ğŸ’¾ Download result
      downloadBtn.onclick = () => {
        const a = document.createElement("a");
        a.href = processedImage.src;
        a.download = "detected.jpg";
        a.click();
      };
    }
  </script>
</body>
</html>
